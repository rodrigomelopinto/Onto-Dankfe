{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'utils')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ds_charts as ds\n",
    "from ds_charts import HEIGHT\n",
    "import numpy as np\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "import seaborn as sns\n",
    "import json\n",
    "import collections\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import timeit\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "data_folder = 'data/gccd/scale/'\n",
    "model_folder = 'data/gccd/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "read csv\n",
      "0.1283506000036141\n",
      "day\n",
      "74.0037755999947\n",
      "month\n",
      "69.8407645000043\n",
      "year\n",
      "68.68519699999888\n",
      "season\n",
      "77.00625589999981\n",
      "country_lat\n",
      "1403.6301183000032\n",
      "country_lon\n",
      "1310.8209181999991\n",
      "avg_temperature\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8632/3156629142.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[0mdata_loop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_observed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m     \u001b[0mgenerate_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_loop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_observed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[0mdata_observed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{data_folder}gccd_scale_{i}_gen.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8632/3156629142.py\u001b[0m in \u001b[0;36mgenerate_variables\u001b[1;34m(model, loop_dataset, edit_dataset)\u001b[0m\n\u001b[0;32m     99\u001b[0m                             \u001b[0minput_values\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0minp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mopIndex\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m                                 \u001b[0medit_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnewvar_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_operation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m                             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m                                 \u001b[0medit_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnewvar_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_operation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewvar_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0medit_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnewvar_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m         \u001b[0miloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"iloc\"\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 723\u001b[1;33m         \u001b[0miloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    724\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1728\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtake_split_path\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1729\u001b[0m             \u001b[1;31m# We have to operate column-wise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1730\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer_split_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1731\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1732\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_single_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer_split_path\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1815\u001b[0m             \u001b[1;31m# scalar value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1816\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mloc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0milocs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1817\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_single_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1819\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_with_indexer_2d_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_single_column\u001b[1;34m(self, loc, value, plane_indexer)\u001b[0m\n\u001b[0;32m   1922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m         \u001b[1;31m# reset the sliced object if unique\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1924\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iset_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1925\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1926\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_single_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_iset_item\u001b[1;34m(self, loc, value)\u001b[0m\n\u001b[0;32m   3763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_iset_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3765\u001b[1;33m         \u001b[0marraylike\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3766\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iset_item_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marraylike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3767\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4504\u001b[0m         \u001b[1;31m# We should never get here with DataFrame value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4505\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4506\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_reindex_for_setitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4508\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_reindex_for_setitem\u001b[1;34m(value, index)\u001b[0m\n\u001b[0;32m  10769\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10770\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10771\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  10772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10773\u001b[0m     \u001b[1;31m# GH#4107\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Domain Knowledge \n",
    "holidays = pd.read_csv('holidays.csv')\n",
    "holidays['date'] =  pd.to_datetime(holidays['date'],format=\"%Y-%m-%d\")\n",
    "\n",
    "day_periods = [(1, (datetime.datetime(2000,1,1,0,0,0),  datetime.datetime(2000,1,1,2,59,59))),\n",
    "           (2, (datetime.datetime(2000,1,1,3,0,0),  datetime.datetime(2000,1,1,5,59,59))),\n",
    "           (3, (datetime.datetime(2000,1,1,6,0,0),  datetime.datetime(2000,1,1,8,59,59))),\n",
    "           (4, (datetime.datetime(2000,1,1,9,0,0),  datetime.datetime(2000,1,1,11,59,59))),\n",
    "           (5, (datetime.datetime(2000,1,1,12,0,0),  datetime.datetime(2000,1,1,14,59,59))),\n",
    "           (6, (datetime.datetime(2000,1,1,15,0,0),  datetime.datetime(2000,1,1,17,59,59))),\n",
    "           (7, (datetime.datetime(2000,1,1,18,0,0),  datetime.datetime(2000,1,1,20,59,59))),\n",
    "           (8, (datetime.datetime(2000,1,1,21,0,0),  datetime.datetime(2000,1,1,23,59,59)))]\n",
    "\n",
    "energy_prices = [(1, (datetime.datetime(2000,1,1,22,0,0),  datetime.datetime(2000,1,1,23,59,59))),\n",
    "           (1, (datetime.datetime(2000,1,1,0,0,0),  datetime.datetime(2000,1,1,7,59,59))),\n",
    "           (2, (datetime.datetime(2000,1,1,8,0,0),  datetime.datetime(2000,1,1,8,59,59))),\n",
    "           (2, (datetime.datetime(2000,1,1,10,30,0),  datetime.datetime(2000,1,1,17,59,59))),\n",
    "           (2, (datetime.datetime(2000,1,1,20,30,0),  datetime.datetime(2000,1,1,21,59,59))),\n",
    "           (3, (datetime.datetime(2000,1,1,9,0,0),  datetime.datetime(2000,1,1,10,29,59))),\n",
    "           (3, (datetime.datetime(2000,1,1,18,0,0),  datetime.datetime(2000,1,1,20,29,59)))]\n",
    "\n",
    "seasons = [(1, (datetime.date(2000,  1,  1),  datetime.date(2000,  3, 20))),\n",
    "           (2, (datetime.date(2000,  3, 21),  datetime.date(2000,  6, 20))),\n",
    "           (3, (datetime.date(2000,  6, 21),  datetime.date(2000,  9, 22))),\n",
    "           (4, (datetime.date(2000,  9, 23),  datetime.date(2000, 12, 20))),\n",
    "           (1, (datetime.date(2000, 12, 21),  datetime.date(2000, 12, 31)))]\n",
    "\n",
    "center_baltimore = (39.30746849825375, -76.61560625253648)\n",
    "\n",
    "# crime_type = [\n",
    "#     (0, ['AUTO THEFT','LARCENY FROM AUTO','LARCENY']),\n",
    "#     (1, ['ROBBERY - STREET', 'ROBBERY - COMMERCIAL','ROBBERY - CARJACKING','BURGLARY','ROBBERY - RESIDENCE']),\n",
    "#     (2, ['COMMON ASSAULT']),\n",
    "#     (3, ['AGG. ASSAULT','ASSAULT BY THREAT']),\n",
    "#     (4, ['ARSON']),\n",
    "#     (5, ['RAPE','SHOOTING']),\n",
    "#     (6, ['HOMICIDE']),\n",
    "# ]\n",
    "\n",
    "crime_type = [\n",
    "    (1, 'LARCENY'), (2,'LARCENY FROM AUTO'), (3,'AUTO THEFT'), (11,'ROBBERY - STREET'), (12,'ROBBERY - COMMERCIAL'), (13,'ROBBERY - CARJACKING'),(14,'ROBBERY - RESIDENCE'),(15,'BURGLARY'),(21,'COMMON ASSAULT'),(31,'ASSAULT BY THREAT'),(32,'AGG. ASSAULT'),(41,'ARSON'),(51,'SHOOTING'),(52,'RAPE'),(61,'HOMICIDE')\n",
    "]\n",
    "weapon_type = [\n",
    "    (0, 'NONE'), (1,'HANDS'), (2,'OTHER'), (3,'KNIFE'), (4,'FIREARM')\n",
    "]\n",
    "\n",
    "# Kept data for operations\n",
    "temp_data = None\n",
    "\n",
    "\n",
    "def generate_variables(model,loop_dataset,edit_dataset):\n",
    "    global temp_data\n",
    "    relations_queue = model['relations']\n",
    "\n",
    "    while len(relations_queue) != 0:\n",
    "        current_relation = relations_queue[0]\n",
    "        print(current_relation['name'])\n",
    "        newvar_name = current_relation['output']\n",
    "        inputs = current_relation['inputs']\n",
    "        groupby = current_relation['groupby']\n",
    "        if set(inputs).issubset(loop_dataset.columns):         # if inputs already exist in the dataset\n",
    "            start_time = timeit.default_timer()\n",
    "            # if len(current_relation['constraint']) == 0:\n",
    "            #     constraint = \"index == index\"\n",
    "            # else:\n",
    "            constraint = current_relation['constraint']\n",
    "            if len(current_relation['constraint']) != 0:\n",
    "                constraint = \"row.\" + constraint\n",
    "            else:\n",
    "                constraint = \"True\"\n",
    "            if len(groupby) == 0: #LAMBDA: no row dependence\n",
    "                for index, op in enumerate(current_relation['operations']):\n",
    "                    if index == 0:\n",
    "                        edit_dataset[newvar_name] = edit_dataset.apply(lambda row: get_operation(op,*zip(inputs,row[inputs])) if pd.eval(constraint, target = row) else np.nan, axis = 1)\n",
    "                    else:\n",
    "                        edit_dataset[newvar_name] = edit_dataset.apply(lambda row: get_operation(op,zip(newvar_name,row[newvar_name])) if pd.eval(constraint, target = row) else np.nan, axis = 1)\n",
    "            else:\n",
    "                needed_rows = current_relation['needsRows']\n",
    "                for i in range(len(loop_dataset)):\n",
    "                    # counter += 1\n",
    "                    row = loop_dataset.loc[i]  # we pass the list to get a DataFrame instead of Series\n",
    "                    if len(groupby) != 0:\n",
    "                        if needed_rows == 'all':\n",
    "                            temp_data = loop_dataset[loop_dataset[groupby] == row.loc[groupby]]\n",
    "                        elif needed_rows < 0:\n",
    "                            temp_data = loop_dataset[loop_dataset[groupby] == row.loc[groupby]].loc[i + needed_rows+1:i]\n",
    "                        else:\n",
    "                            temp_data = loop_dataset[loop_dataset[groupby] == row.loc[groupby]].loc[i:i + needed_rows-1] # get necessary rows to temp_data\n",
    "                    # else:\n",
    "                    #     if needed_rows < 0: \n",
    "                    #         temp_data = dataset.loc[i+ needed_rows:i]\n",
    "                    #     else:    \n",
    "                    #         temp_data = dataset.loc[i:i + needed_rows]\n",
    "                    if pd.eval(constraint, target = row) == False:\n",
    "                        edit_dataset.loc[i,newvar_name] = np.nan\n",
    "                        continue\n",
    "                    else:\n",
    "                        for opIndex, op in enumerate(current_relation['operations']):\n",
    "                            input_values =  [row.loc[inp] for inp in inputs]\n",
    "                            if opIndex == 0:\n",
    "                                edit_dataset.loc[i,newvar_name] = get_operation(op,*zip(inputs,input_values))\n",
    "                            else:\n",
    "                                edit_dataset.loc[i,newvar_name] = get_operation(op,zip(newvar_name,edit_dataset.loc[i,newvar_name]))\n",
    "            relations_queue = relations_queue[1:]\n",
    "            loop_dataset = edit_dataset.copy(deep=True)\n",
    "            print(timeit.default_timer() - start_time)\n",
    "        else:\n",
    "            # send to the bottom of the queue\n",
    "            relations_queue.append(relations_queue.pop(relations_queue.index(current_relation)))\n",
    "        \n",
    "def get_operation(code,*values):\n",
    "    if code == '+':\n",
    "        sum_values = [values[i][1] for i,x in enumerate(values)]\n",
    "        return np.sum(sum_values)\n",
    "    elif code == 'positive_sum':\n",
    "        sum_values = [values[i][1] for i,x in enumerate(values) if values[i][1] >= 0]\n",
    "        return np.sum(sum_values)\n",
    "    elif code == 'negative_sum':\n",
    "        sum_values = [values[i][1] for i,x in enumerate(values) if values[i][1] <= 0]\n",
    "        return np.sum(sum_values)\n",
    "    elif code == '-':\n",
    "        return values[0][1] - values[1][1]\n",
    "    elif code == '*':\n",
    "        prod_values = [values[i][1] for i,x in enumerate(values)]\n",
    "        return np.prod(prod_values)\n",
    "    elif code == '/':\n",
    "        return round(values[0][1] / values[1][1],2)\n",
    "    elif code == '>=':\n",
    "        return values[0][1] >= values[1][1]\n",
    "    elif code == 'datediff':\n",
    "        return relativedelta(values[0][1],values[1][1])\n",
    "    elif code == 'years':\n",
    "        return values[0][1].years\n",
    "    elif code == 'months':\n",
    "        return values[0][1].years * 12 + values[0][1].months\n",
    "    elif code == 'getHour':\n",
    "        return values[0][1].hour\n",
    "    elif code == 'getDay':\n",
    "        return values[0][1].day\n",
    "    elif code == 'getMonth':\n",
    "        return values[0][1].month\n",
    "    elif code == 'getYear':\n",
    "        return values[0][1].year\n",
    "    elif code == 'getWeekday':\n",
    "        return values[0][1].dayofweek\n",
    "    elif code == 'getSeason':\n",
    "        return getSeason(values[0][1],seasons)\n",
    "    elif code == 'getDayPeriod':\n",
    "        return getDayPeriod(values[0][1],day_periods)\n",
    "    elif code == 'getEnergyPrice':\n",
    "        return getDayPeriod(values[0][1],energy_prices)\n",
    "    elif code == 'getHoliday':\n",
    "        return generateHoliday(values[0][1],values[1][1],holidays)\n",
    "    elif code == 'divide_by_30':\n",
    "        return values[0][1] / 30\n",
    "    elif code == 'getAverage':\n",
    "        return generateAverage(values[0][0])\n",
    "    elif code == 'getMax':\n",
    "        return generateMax(values[0][0])\n",
    "    elif code == 'getMin':\n",
    "        return generateMin(values[0][0])\n",
    "    elif code == 'getStd':\n",
    "        return generateStd(values[0][0])\n",
    "    elif code == 'generateAvg_2weeks':\n",
    "        return generateAverage2Weeks(values[0][1],values[1][1])\n",
    "    elif code == 'generateAvg_2w_100k':\n",
    "        return values[0][1] * 100000 / values[1][1]\n",
    "    elif code == 'generateSum_2weeks':\n",
    "        return generateCumulative2Weeks(values[0][1],values[1][1])\n",
    "    elif code == 'generateHighRisk_2weeks':\n",
    "        return generateHighRisk(values[0][1],values[1][1],14)\n",
    "    elif code == 'getLastYearTemp':\n",
    "        return generateLastYearTemp(values[0][1],values[1][1],12)\n",
    "    elif code == 'generateSum_2w_100k':\n",
    "        return values[0][1] * 100000 / values[1][1]\n",
    "    elif code == 'generateEstadio_8ed':\n",
    "        return generateFromTable(values[0][1],values[1][1],estadio)\n",
    "    elif code == 'generateN_8ed':\n",
    "        return generateN8ed(values[0][1])\n",
    "    elif code == 'getDistanceBaltimore':\n",
    "        return haversine(values[0][1],values[1][1],center_baltimore[0],center_baltimore[1])\n",
    "    elif code == 'getCrimeType':\n",
    "        return [x[0] for x in crime_type if x[1] == values[0][1]][0]\n",
    "    elif code == 'getWeapon':\n",
    "        return [x[0] for x in weapon_type if x[1] == values[0][1]][0]\n",
    "    elif code == 'getCases100k':\n",
    "        return values[0][1] * 100000 / values[1][1]\n",
    "    elif code == 'getCurrentRisk':\n",
    "        return values[0][1] > 120\n",
    "    elif code == 'getAverageDiffPos':\n",
    "        return values[0][1] >= 0\n",
    "    elif code == 'generatePM25_safe':\n",
    "        return values[0][1] >= 35\n",
    "    elif code == 'generatePM10_safe':\n",
    "        return values[0][1] >= 150\n",
    "    elif code == 'generateSO2_safe':\n",
    "        return values[0][1] >= 0.14\n",
    "    else:\n",
    "        return lambda *x : x\n",
    "\n",
    "\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "      R = 6372.8\n",
    "      dLat = radians(lat2 - lat1)\n",
    "      dLon = radians(lon2 - lon1)\n",
    "      lat1 = radians(lat1)\n",
    "      lat2 = radians(lat2)\n",
    "      a = sin(dLat/2)**2 + cos(lat1)*cos(lat2)*sin(dLon/2)**2\n",
    "      c = 2*asin(sqrt(a))\n",
    "      return R * c\n",
    "\n",
    "def generateFromTable(t,n,table):\n",
    "    return table[t][n]\n",
    "\n",
    "def generateN8ed(gg_p):\n",
    "    if gg_p == 0:\n",
    "        return 1\n",
    "    elif gg_p >= 1 and gg_p <= 2:\n",
    "        return 2\n",
    "    elif gg_p >= 3 and gg_p <= 6:\n",
    "        return 3\n",
    "    elif gg_p >= 7 and gg_p <= 15:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "def generateAverage(column):\n",
    "    return np.mean(temp_data[column].to_list())\n",
    "def generateMax(column):\n",
    "    return np.max(temp_data[column].to_list())\n",
    "def generateMin(column):\n",
    "    return np.min(temp_data[column].to_list())\n",
    "def generateStd(column):\n",
    "    return np.std(temp_data[column].to_list())\n",
    "\n",
    "def getSeason(date,season_dict):\n",
    "    date = date.replace(year=2000)\n",
    "    return next(season for season, (start, end) in season_dict\n",
    "                if start <= date <= end)\n",
    "def getDayPeriod(date,season_dict):\n",
    "    date = date.replace(year=2000,month=1,day=1)\n",
    "    return next(season for season, (start, end) in season_dict\n",
    "                if start <= date <= end)\n",
    "\n",
    "def generateAverage2Weeks(date,cases):\n",
    "    lastCases = temp_data['cases'].to_list()\n",
    "    return np.mean(lastCases)\n",
    "\n",
    "def generateHighRisk(date,sum_2weeks,offset):\n",
    "    high_risk_day = date + datetime.timedelta(days=offset)\n",
    "    high_risk_cumulative = temp_data[temp_data['current_date'] == high_risk_day]\n",
    "    if len(high_risk_cumulative) == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return high_risk_cumulative.iloc[0]['sum_2w_100k'] >= 120.0\n",
    "\n",
    "def generateLastYearTemp(date,temp,offset):\n",
    "    last_year_day = date - relativedelta(months=offset)\n",
    "    last_year_record = temp_data[temp_data['current_date'] == last_year_day]\n",
    "    if len(last_year_record) == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return last_year_record.iloc[0]['temperature']\n",
    "\n",
    "def generateCumulative2Weeks(date,cases):\n",
    "    lastCases = temp_data['cases'].to_list()\n",
    "    return np.sum(lastCases)\n",
    "\n",
    "def generateHoliday(date,country,holiday_data):\n",
    "    return holiday_data.loc[(holiday_data['date'] == date) & (holiday_data['country'] == country)].any().all()\n",
    "\n",
    "# Get dataset\n",
    "for i in range(6,9):\n",
    "    print(i)\n",
    "    start_time = timeit.default_timer()\n",
    "    data = pd.read_csv(f'{data_folder}gccd_scale_{i}.csv',parse_dates=True, infer_datetime_format=True)\n",
    "    print('read csv')\n",
    "    print(timeit.default_timer() - start_time)\n",
    "\n",
    "    # Getting ER Model of case study data\n",
    "    f = open(f'{model_folder}gccd_model.json')\n",
    "    model = json.load(f)\n",
    "\n",
    "    entity_name_list = [entity['name'] for entity in model['entities']]\n",
    "    # Raise Error if entities do not match columns:\n",
    "    if collections.Counter(entity_name_list) != collections.Counter(data.columns.to_list()):\n",
    "        raise ValueError(\"Entities and Columns do not have the same size.\")\n",
    "\n",
    "\n",
    "    not_observed = [entity['name'] for entity in model['entities'] if not entity['observed']]\n",
    "    created_vars = [relation['output'] for relation in model['relations']]\n",
    "    date_columns = [entity['name'] for entity in model['entities'] if entity['type'] == 'datetime']\n",
    "    data['current_date'] = pd.to_datetime(data['current_date'], format = \"%Y-%m-%d %H:%M:%S\")\n",
    "    data_observed = data.drop(columns = not_observed)\n",
    "\n",
    "    data_loop = data_observed.copy(deep=True)\n",
    "    start_time = timeit.default_timer()\n",
    "    generate_variables(model,data_loop,data_observed)\n",
    "    start_time = timeit.default_timer()\n",
    "    data_observed.to_csv(f'{data_folder}gccd_scale_{i}_gen.csv',index=False)\n",
    "    print('save csv')\n",
    "    print(timeit.default_timer() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae305f4dee197bdc0c916b004f5792eca0da2328f3eb5fe8e31b308819fc7eb2"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
