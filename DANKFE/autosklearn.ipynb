{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'utils')\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.svm import LinearSVC\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sklearn.metrics as metrics\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "import ds_charts as ds\n",
    "from ds_charts import plot_evaluation_results\n",
    "import itertools as it\n",
    "import timeit\n",
    "import autosklearn.classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = ''\n",
    "dataset = 'aq/aq_prov_base'\n",
    "file_name = '0'\n",
    "data_folder = f'data/{dataset}/'\n",
    "# image_basefile = f'ecdc_covid_{dataset}'\n",
    "# image_dir = f'images/{image_basefile}/{suffix}/'\n",
    "\n",
    "\n",
    "data = pd.read_csv(f'{data_folder}{file_name}{suffix}.csv',parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "data = data.drop(columns=['current_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Tratamento de missing values\n",
    "# variable_types = ds.get_variable_types(data)\n",
    "# inverted_variable_types = {val: key for key in variable_types for val in variable_types[key]}\n",
    "# missing_list = data.isna().sum()[data.isna().sum() != 0].index.to_list()\n",
    "# print(data.isna().sum()[data.isna().sum() != 0])\n",
    "# missing_types = [(i,inverted_variable_types[i]) for i in missing_list]\n",
    "# missing_types\n",
    "\n",
    "# Fill deaths and cases with 0 for MVs\n",
    "# data['cases'] = data['cases'].fillna(0)\n",
    "# data['deaths'] = data['deaths'].fillna(0)\n",
    "# data['ratio'] = data['ratio'].fillna(0)\n",
    "# data['cases_per_100k'] = data['cases_per_100k'].fillna(0)\n",
    "# Drop rows where there is no high_risk (class)\n",
    "# data = data.dropna(subset=['high_risk_2w','avg_2weeks'])\n",
    "# data = data.dropna(subset=['renewable_percentage'])\n",
    "data = data.drop(columns=['Distance','Distance_Prov'])\n",
    "# data = data.dropna(subset=['last_year_temp','one_year_diff'])\n",
    "\n",
    "\n",
    "# Preprocessamento - encoding de strings\n",
    "# le = LabelEncoder()\n",
    "# # data['city'] = le.fit_transform(data['city'])\n",
    "# data['country'] = le.fit_transform(data['country'])\n",
    "# # data['description'] = le.fit_transform(data['description'])\n",
    "# # data['weapon'] = le.fit_transform(data['weapon'])\n",
    "# # data['district'] = le.fit_transform(data['district'])\n",
    "# # data['neighborhood'] = le.fit_transform(data['neighborhood'])\n",
    "\n",
    "# data['high_risk_2w'] = data['high_risk_2w'].astype(bool)\n",
    "\n",
    "print(data.isna().sum()[data.isna().sum() != 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALARM           int64\n",
       "CO_Mean       float64\n",
       "CO_Min        float64\n",
       "CO_Max        float64\n",
       "CO_Std        float64\n",
       "NO2_Mean      float64\n",
       "NO2_Min       float64\n",
       "NO2_Max       float64\n",
       "NO2_Std       float64\n",
       "O3_Mean       float64\n",
       "O3_Min        float64\n",
       "O3_Max        float64\n",
       "O3_Std        float64\n",
       "PM2.5_Mean    float64\n",
       "PM2.5_Min     float64\n",
       "PM2.5_Max     float64\n",
       "PM2.5_Std     float64\n",
       "PM10_Mean     float64\n",
       "PM10_Min      float64\n",
       "PM10_Max      float64\n",
       "PM10_Std      float64\n",
       "SO2_Mean      float64\n",
       "SO2_Min       float64\n",
       "SO2_Max       float64\n",
       "SO2_Std       float64\n",
       "GbCity          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3612.413715246\n",
      "223.72186156099997\n"
     ]
    }
   ],
   "source": [
    "# O auto-sklearn apenas aceita valores num√©ricos\n",
    "target = 'ALARM'\n",
    "y: np.ndarray = data.pop(target).values\n",
    "X: np.ndarray = data.values\n",
    "labels: np.ndarray = pd.unique(y)\n",
    "\n",
    "trnX, tstX, trnY, tstY = train_test_split(X, y, stratify = y, test_size= 0.3, random_state = 0)\n",
    "cls = autosklearn.classification.AutoSklearnClassifier(seed = 0, n_jobs=2)\n",
    "start_time = timeit.default_timer()\n",
    "cls.fit(trnX, trnY)\n",
    "print(timeit.default_timer() - start_time)\n",
    "start_time = timeit.default_timer()\n",
    "predictions = cls.predict(tstX)\n",
    "print(timeit.default_timer() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_fold(y_train,y_prediction,store,model):\n",
    "    store[model]['precision'].append(metrics.precision_score(y_train,y_prediction))\n",
    "    store[model]['recall'].append(metrics.recall_score(y_train,y_prediction))\n",
    "    store[model]['accuracy'].append(metrics.accuracy_score(y_train,y_prediction))\n",
    "    store[model]['auc'].append(metrics.roc_auc_score(y_train,y_prediction))\n",
    "    store[model]['F1'].append(metrics.f1_score(y_train,y_prediction))\n",
    "    return store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RF': {'precision': [], 'recall': [], 'accuracy': [], 'auc': [], 'F1': []},\n",
       " 'GB': {'precision': [], 'recall': [], 'accuracy': [], 'auc': [], 'F1': []},\n",
       " 'AS': {'precision': [0.9493638676844783],\n",
       "  'recall': [0.9341512268402604],\n",
       "  'accuracy': [0.930672268907563],\n",
       "  'auc': [0.9298096958171339],\n",
       "  'F1': [0.941696113074205]}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores = {\n",
    "    # 'NB':  {'precision': [], 'recall' : [], 'accuracy': [], 'auc': []},\n",
    "    # 'KNN': {'precision': [], 'recall' : [], 'accuracy': [], 'auc': []},\n",
    "    # 'DT':  {'precision': [], 'recall' : [], 'accuracy': [], 'auc': []},\n",
    "    'RF':  {'precision': [], 'recall' : [], 'accuracy': [], 'auc': [], 'F1': []},\n",
    "    'GB':  {'precision': [], 'recall' : [], 'accuracy': [], 'auc': [], 'F1': []},\n",
    "    'AS':  {'precision': [], 'recall' : [], 'accuracy': [], 'auc': [], 'F1': []},\n",
    "}\n",
    "\n",
    "get_scores_fold(tstY,predictions,model_scores,'AS')\n",
    "\n",
    "print(model_scores['AS']['precision'])\n",
    "print(model_scores['AS']['recall'])\n",
    "print(model_scores['AS']['accuracy'])\n",
    "print(model_scores['AS']['auc'])\n",
    "print(model_scores['AS']['F1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# picklestring = f\"{data_folder}_{file_name}\".replace('/','_')\n",
    "# import pickle\n",
    "# with open(f'askl_{picklestring}_classifier.p', 'wb') as handle:\n",
    "#     pickle.dump(cls, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# with open(f'askl_{picklestring}_predictions.p', 'wb') as handle:\n",
    "#     pickle.dump(predictions, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# cls = pd.read_pickle(\"askl_base_classifier_mdai.p\")\n",
    "\n",
    "# cls.leaderboard(detailed=True, ensemble_only=False).to_csv(f\"{data_folder}{file_name}_autoskl.csv\")\n",
    "# print(cls.sprint_statistics())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae305f4dee197bdc0c916b004f5792eca0da2328f3eb5fe8e31b308819fc7eb2"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
